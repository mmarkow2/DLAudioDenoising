\documentclass[UTF8]{article}
\DeclareMathAlphabet{\mathpzc}{OT1}{pzc}{m}{it}
\usepackage{bbold}
\usepackage{bm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx} 
\usepackage{subfigure}
\usepackage{float}
\usepackage[colorlinks]{hyperref}
\title{Final Project}
\author{Matthew Markowitz, Lifu Xiao}
\date{\today}

\begin{document}
\maketitle


\section{Introduction}
The database is a set of noisy recordings, which have poor quality for further usage. So it make sense  to improve them. In order to remove the noise, we propose to use online dictionary learning.\\

There were many challenges involved with this problem. One problem involved the large number of samples that were needed to begin the dictionary updates. Unfortunately, we can not begin training the dictionary until there are no zero elements in our diagonal matrix $A$. This means that until every single dimension must have at least one alpha with a non-zero element in it. To overcome this, we refused to update the dictionary until all the zero elements were filled. However, this is also not ideal because this requires substantially more training data as the window size for our audio increased. Experimentally, this can be overcome by adding a random small constant to our $A$ before we start (such as 0.000000001), however, this is little to no theoretical backing for this, so we did not take this route.\\

Deep recurrent neural networks\cite{valentini2016speech} have good performance on extracting acoustic features from noisy data. But it have a high computation cost. Another widely used method is spectral subtraction.

\section{Problem Statement}
We used a python library known as librosa to import our audio\cite{valentini2016speech}. The audio recordings found in our test set had a sampling rate of 22050. This meant that every second of audio held approximately 22,000 numbers to represent it. For this reason, down sampling became necessary. Although some sacrifice in audio quality was necessary, we were able to reduce the sampling rate to 5,000, which made our calculations more feasible. The 5,000 points per second was still computationally intensive, but we found that we could break each second into X millisecond windows to ease computation further without sacrificing much quality. We found that a window size of 50 points or 50/5,000 = 1/100 second windows worked well for our dataset.


\section{Algorithm}

\subsection{Data Preparation}

Initializing the $\bm{A}_0 \in \mathbb{R}^{k \times k} \text{ and } \bm{B}_0 \in \mathbb{R}^{m \times k} \text{ as } \vec{\bm{0}} $\\
$k$ is atoms number and $m$ is the dictionary size.

\subsection{Sparse Coding}
When each $x_t$ come, using LARS\cite{scikit-learn} to calculate
\[
	\alpha_t \triangleq \mathop{\arg\min}\limits_{\alpha\in R^k} \frac{1}{2} \| \bm{x}_t - \bm{D}_{t-1} \alpha  \|^2_2 + k \cdot \lambda \|\alpha\|_1
\]
where $\bm{x} \in \mathbb{R}^{m}, \bm{D} \in \mathbb{R}^{m \times k} \text{ and } t \leq T \text{(maximum number of iterations)}$
\\
Then updating $\bm{A}, \bm{B}$ by
\[\bm{A}_t \leftarrow \bm{A}_{t-1} + \alpha_t \alpha_t^T\]
\[\bm{B}_t \leftarrow \bm{B}_{t-1} + \bm{x}_t \alpha_t^T\]

\subsection{Dictionary Update}
\[\bm{D}_t \triangleq \mathop{\arg\min}\limits_{\bm{D} \in C} \frac{1}{t} \sum{ \frac{1}{2} \| \bm{x}_i - \bm{D} \alpha_i  \|^2_2 + \lambda \|\alpha\|_1}
\]
Where $C \triangleq {\bm{D} \in \mathbb{R}^{m \times k} \text{ s.t. } \forall j = 1, ..., k, \bm{d}_j^T\bm{d}_j \leq 1}$ to ensure the convex.
\\
Using block-coordinate descent to update dictionary
Extracting columns of $\bm{A} \text{ and } \bm{B}$
\[\bm{A} = [\bm{a}_1, ..., \bm{a}_k] \in \mathbb{R}^{k \times k}\]
\[\bm{B} = [\bm{b}_1, ..., \bm{b}_k] \in \mathbb{R}^{k \times k}\]
for each column from $j = 1 \Rightarrow k$
\[\bm{u_j} \leftarrow \frac{1}{A[j, j]}(\bm{b}_j - \bm{Da}_j) + \bm{d}_j\]
\[\bm{d}_j \leftarrow \frac{1}{\max(\|\bm{u}_j\|_2, 1)}\bm{u}_j\]
return $\bm{D}$ for next iteration


\section{Experiments}

To visualize our result, we picked a 6 seconds segment of the output audio.
The Original, Downsampled figures and the Clean data which is used for a baseline are as follows.
\begin{figure}[H]
    \centering
    \subfigure[Original]{
        \label{Fig.sub1.1}
        \includegraphics[width=0.8\textwidth]{image/Original.png}}
    \subfigure[Downsampled]{
        \label{Fig.sub1.2}
        \includegraphics[width=0.8\textwidth]{image/Downsampled.png}}
    \subfigure[CleanData]{
        \label{Fig.sub1.3}
        \includegraphics[width=0.9\textwidth]{image/Clean.png}}
    \caption{Original , Downsampled and the Clean data}
\end{figure}



We choose $k = 500 \text{ and } m = 50$ for the online dictionary learning step and the result generated by different $\lambda$ are presented in Figure 2.


\begin{figure}[H]
    \centering
    \subfigure[$\lambda = 0.005$]{
        \label{Fig.sub2.1}
        \includegraphics[width=0.9\textwidth]{image/0_0001.png}}
    \subfigure[$\lambda = 0.025$]{
        \label{Fig.sub2.2}
        \includegraphics[width=0.9\textwidth]{image/0_0005.png}}
    \subfigure[$\lambda = 0.035$]{
        \label{Fig.sub2.3}
        \includegraphics[width=0.9\textwidth]{image/0_0007.png}}
    \subfigure[$\lambda = 0.05$]{
        \label{Fig.sub2.4}
        \includegraphics[width=0.9\textwidth]{image/0_001.png}}
    \caption{Output}
\end{figure}

%  Reference
\bibliographystyle{unsrt}
\bibliography{reference}
\nocite{*}

\end{document}